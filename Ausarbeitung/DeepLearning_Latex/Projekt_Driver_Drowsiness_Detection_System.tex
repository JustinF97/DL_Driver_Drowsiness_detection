\section{Projekt/Driver/Drowsiness/Detection/System}

Für das Projekt 'Driver Drowsiness Detection System', wird ein Programm erstellt, welches mit einer Webcam erkennen , ob die Person im Auto ihre Augen geöffnet oder geschlossen hat.

Falls die Augen des Fahrers oder der Fahrerin eine 
bestimmte Zeit nicht erfasst werden können, werden die Insassen des Autos mit einem Geräusch gewarnt.

\subsection{Programmierung/Installierung}

Für das Python Projekt 'Driver Drowsiness Detection System', wird das Programm 'OpenCV' benötigt. 

OpenCV ist eine Programmbibliothek mit Algorithmen für die Bildverarbeitung und Computer Vision.

Sie kann für die Programmiersprachen C, C++, Python und Java genutzt werden.

Die Bibliothek befasst sich mit der Gesichtserkennung, 3D-Funktionalität und Funktionen für die Kamerakalibrierung.

Das Deep Learning Modul von OpenCV, zum Beispiel 'YOLO', empfängt die Bilddaten und kann bis zu 80 verschiedene Objekte Identifizieren.

Mit OpenCV werden Bilder von unterschiedlichen Augen gesammelt, um diese in ein Deep Learning Model umzuwandeln, so dass später erkannt werden kann, ob die Augen von den Personen geöffnet oder geschlossen sind.

Der erste Schritt des Projekts ist es, von den verschiedenen Augen, eine Datenbank zu erstellen.

So werden mehrere tausende Bilder von Augen 
abgespeichert, zu einem 'Data Set' verpackt und daraufhin dem Programm beigebracht. 

Das Programm kann so später jegliche Augen von Personen erkennen und auslesen.   


Das Model des Projektes wird mit Keras (Convolutional Neural Networks) erstellt. 

Keras ist eine Open Source Deep-Learning Bibliothek, in der Programmiersprache Python.

Keras kann für TensorFlow, Microsoft Cognitive Toolkit und Theano genutzt werden.


Eine CNN besteht aus einem Input-, Output- und einem Hidden-Layer welche mehrere Schichten haben kann.

So wird ein Filter für die Layers genutzt um eine 2D Matrix zu erstellen. 

\newpage
Keras imports für das Projekt:
\begin{lstlisting}
from keras.preprocessing import image
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.models import load_model
\end{lstlisting}

Voraussetzungen für das Projekt:
Python, Webcam, OpenCV (Gesicht/Augen Erkennung), TensorFlow (für Keras), Keras (Model) und Pygame (Sound).\cite{b1}


\subsection{Ablauf des Programmes}

\subsection{Schritt 1: Verwendung der Kamera, als Input}


Durch die Webcam werden die empfangenden Bilder als Input für das Programm verwendet. 

Über OpenCv, wird sich mit der Webcam verbunden über die Methode.
\begin{lstlisting}
Methode: cv2.VideoCapture(o) 
\end{lstlisting}

Auch muss jedes Frame, welches gespeichert wird, in einer Variable abgespeichert werden.
\begin{lstlisting}
Methode: cap.read()
\end{lstlisting}


\subsection{Schritt 2: Gesicht erkennen und eine Region of Interest (ROI) erstellen.}

Um in der Webcam das Gesicht zu erkennen, muss das Bild zu einem Grayscale umgewandelt werden, denn OpenCv arbeitet mit Grauen Images. 

Es werden keine Farben benötigt um die Gesichter zu erkennen. 

Mit der Methode 'haar cascade' wird das Gesicht der Person in der Webcam erkannt. 

\begin{lstlisting}
Methode: 

(face = cv2.CascadeClassifier / 

faces = face.detectMultiScale(gray))
\end{lstlisting}

Durch die 'haar cascade' Methoden erhält man x und y Array Werte zurück. 

Über die empfangenden Array Werte kann nun ein Rahmen zur Erkennung des Gesichtes erstellt werden. 


\subsection{Schritt 3: Im Region of Interest (ROI) die Augen erkennen.}

Genau wie im Schritt 2 wird nun auch ein ROI für die Augen erstellt. 

\begin{lstlisting}
Methode: (left_eye = leye.detectMultiscale(gray)).
\end{lstlisting}

Nun werden die Daten der Augen erfasst und ein Rahmen um die Augen erstellt, 
umso die benötigten Informationen der Augen auszulesen.

\begin{lstlisting}
Methode: l_eye = frame[ y : y+h, x : x+w] 
\end{lstlisting}
 
l\_eye beinhaltet nur die Daten von den Augen.

Diese Daten werden in CNN hochgeladen, so das erkannt wird ob die Augen offen oder geschlossen sind. 

Mit dem rechten Auge r\_eye wird der Ablauf wie für das linke Auge wiederholt.

\subsection{Schritt 4: Classifier soll erkennen, ob das Auge offen oder geschlossen ist}

Damit der Classifier die Augen überprüfen kann, werden die Daten in CNN hochgeladen. 

Zuvor werden die Daten noch in das richtige Format umgewandelt. 

Das Grayscale wird zu einem 24*24 Pixel Bild komprimiert. 

Nun kann das Programm auf der Webcam erkennen, ob die Person ihre Augen offen oder geschlossen hat.
\begin{lstlisting}
Augen offen  (1)

Augen geschlossen (0)
\end{lstlisting}

\subsection*{Schritt 5: Ausrechnen der Werte um zu erkennen, wann die Person unaufmerksam ist.}

Jedes Mal, wenn die Person in der Kamera ihre Augen schließt, wird ein 'Counter' hochgezählt und beim Öffnen runter gezählt. 

Erreicht der Counter den Wert 15, ertönt ein Warnsignal. 

Zudem wird der  aktuelle Wert auf dem Display angezeigt.
\begin{lstlisting}
Methode:  cv2.putText()
\end{lstlisting}

Mit dieser Methode wird der Text auf dem Display angezeigt.\cite{b1}
\newline
\newline

















